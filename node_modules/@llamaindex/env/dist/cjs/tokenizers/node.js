// Note: This is using th WASM implementation of tiktoken which is 60x faster
"use strict";
Object.defineProperty(exports, "__esModule", {
    value: true
});
function _export(target, all) {
    for(var name in all)Object.defineProperty(target, name, {
        enumerable: true,
        get: all[name]
    });
}
_export(exports, {
    Tokenizers: function() {
        return _types.Tokenizers;
    },
    tokenizers: function() {
        return tokenizers;
    }
});
const _types = require("./types.js");
const _tiktoken = require("tiktoken");
class TokenizerSingleton {
    defaultTokenizer;
    constructor(){
        const encoding = (0, _tiktoken.get_encoding)("cl100k_base");
        this.defaultTokenizer = {
            encode: (text)=>{
                return encoding.encode(text);
            },
            decode: (tokens)=>{
                const text = encoding.decode(tokens);
                return new TextDecoder().decode(text);
            }
        };
    }
    tokenizer(encoding) {
        if (encoding && encoding !== _types.Tokenizers.CL100K_BASE) {
            throw new Error(`Tokenizer encoding ${encoding} not yet supported`);
        }
        return this.defaultTokenizer;
    }
}
const tokenizers = new TokenizerSingleton();
