import { CustomEvent, Tokenizer } from '@llamaindex/env';
import { ChatMessage, ToolCall, ToolOutput, ChatResponse, ChatResponseChunk } from '../llms/index.js';
import { TextNode } from '../schema/index.js';

/**
 * EventCaller is used to track the caller of an event.
 */
declare class EventCaller {
    #private;
    readonly caller: unknown;
    readonly parent: EventCaller | null;
    readonly id: `${string}-${string}-${string}-${string}-${string}`;
    private constructor();
    get computedCallers(): unknown[];
    static create(caller: unknown, parent: EventCaller | null): EventCaller;
}

type UUID = `${string}-${string}-${string}-${string}-${string}`;
type JSONValue = string | number | boolean | JSONObject | JSONArray;
type JSONObject = {
    [key: string]: JSONValue;
};
type JSONArray = Array<JSONValue>;

type LLMStartEvent = {
    id: UUID;
    messages: ChatMessage[];
};
type LLMToolCallEvent = {
    toolCall: ToolCall;
};
type LLMToolResultEvent = {
    toolCall: ToolCall;
    toolResult: ToolOutput;
};
type LLMEndEvent = {
    id: UUID;
    response: ChatResponse;
};
type LLMStreamEvent = {
    id: UUID;
    chunk: ChatResponseChunk;
};
type ChunkingStartEvent = {
    text: string[];
};
type ChunkingEndEvent = {
    chunks: string[];
};
type NodeParsingStartEvent = {
    documents: TextNode[];
};
type NodeParsingEndEvent = {
    nodes: TextNode[];
};
interface LlamaIndexEventMaps {
    "llm-start": LLMStartEvent;
    "llm-end": LLMEndEvent;
    "llm-tool-call": LLMToolCallEvent;
    "llm-tool-result": LLMToolResultEvent;
    "llm-stream": LLMStreamEvent;
    "chunking-start": ChunkingStartEvent;
    "chunking-end": ChunkingEndEvent;
    "node-parsing-start": NodeParsingStartEvent;
    "node-parsing-end": NodeParsingEndEvent;
}
declare class LlamaIndexCustomEvent<T = any> extends CustomEvent<T> {
    reason: EventCaller | null;
    private constructor();
    static fromEvent<Type extends keyof LlamaIndexEventMaps>(type: Type, detail: LlamaIndexEventMaps[Type]): LlamaIndexCustomEvent<any>;
}
type EventHandler<Event> = (event: LlamaIndexCustomEvent<Event>) => void;
declare class CallbackManager {
    #private;
    on<K extends keyof LlamaIndexEventMaps>(event: K, handler: EventHandler<LlamaIndexEventMaps[K]>): this;
    off<K extends keyof LlamaIndexEventMaps>(event: K, handler: EventHandler<LlamaIndexEventMaps[K]>): this;
    dispatchEvent<K extends keyof LlamaIndexEventMaps>(event: K, detail: LlamaIndexEventMaps[K]): void;
}

declare const Settings: {
    tokenizer: Tokenizer;
    withTokenizer<Result>(tokenizer: Tokenizer, fn: () => Result): Result;
    chunkSize: number | undefined;
    withChunkSize<Result>(chunkSize: number, fn: () => Result): Result;
    callbackManager: CallbackManager;
    withCallbackManager<Result>(callbackManager: CallbackManager, fn: () => Result): Result;
};

export { CallbackManager, type JSONArray, type JSONObject, type JSONValue, type LLMEndEvent, type LLMStartEvent, type LLMStreamEvent, type LLMToolCallEvent, type LLMToolResultEvent, type LlamaIndexEventMaps, Settings };
