import { EngineResponse, MetadataMode } from "@llamaindex/core/schema";
import type { ServiceContext } from "../ServiceContext.js";
import { PromptMixin } from "../prompts/Mixin.js";
import type { TextQaPrompt } from "./../Prompt.js";
import type { BaseSynthesizer, SynthesizeQuery } from "./types.js";
export declare class MultiModalResponseSynthesizer extends PromptMixin implements BaseSynthesizer {
    serviceContext?: ServiceContext;
    metadataMode: MetadataMode;
    textQATemplate: TextQaPrompt;
    constructor({ serviceContext, textQATemplate, metadataMode, }?: Partial<MultiModalResponseSynthesizer>);
    protected _getPrompts(): {
        textQATemplate: TextQaPrompt;
    };
    protected _updatePrompts(promptsDict: {
        textQATemplate: TextQaPrompt;
    }): void;
    synthesize(query: SynthesizeQuery, stream: true): Promise<AsyncIterable<EngineResponse>>;
    synthesize(query: SynthesizeQuery, stream?: false): Promise<EngineResponse>;
}
