"use strict";
Object.defineProperty(exports, "__esModule", {
    value: true
});
Object.defineProperty(exports, "LlamaCloudIndex", {
    enumerable: true,
    get: function() {
        return LlamaCloudIndex;
    }
});
const _RetrieverQueryEngine = require("../engines/query/RetrieverQueryEngine.js");
const _LlamaCloudRetriever = require("./LlamaCloudRetriever.js");
const _config = require("./config.js");
const _utils = require("./utils.js");
const _api = require("@llamaindex/cloud/api");
const _nodeparser = require("@llamaindex/core/node-parser");
const _env = require("@llamaindex/env");
const _Settings = require("../Settings.js");
const _OpenAIEmbedding = require("../embeddings/OpenAIEmbedding.js");
class LlamaCloudIndex {
    params;
    constructor(params){
        this.params = params;
        (0, _utils.initService)(this.params);
    }
    async waitForPipelineIngestion(verbose = _Settings.Settings.debug, raiseOnError = false) {
        const pipelineId = await this.getPipelineId(this.params.name, this.params.projectName);
        if (verbose) {
            console.log("Waiting for pipeline ingestion: ");
        }
        while(true){
            const pipelineStatus = await _api.PipelinesService.getPipelineStatusApiV1PipelinesPipelineIdStatusGet({
                pipelineId
            });
            if (pipelineStatus.status === "SUCCESS") {
                if (verbose) {
                    console.log("Pipeline ingestion completed successfully");
                }
                break;
            }
            if (pipelineStatus.status === "ERROR") {
                if (verbose) {
                    console.error("Pipeline ingestion failed");
                }
                if (raiseOnError) {
                    throw new Error("Pipeline ingestion failed");
                }
            }
            if (verbose) {
                process.stdout.write(".");
            }
            await new Promise((resolve)=>setTimeout(resolve, 1000));
        }
    }
    async waitForDocumentIngestion(docIds, verbose = _Settings.Settings.debug, raiseOnError = false) {
        const pipelineId = await this.getPipelineId(this.params.name, this.params.projectName);
        if (verbose) {
            console.log("Loading data: ");
        }
        const pendingDocs = new Set(docIds);
        while(pendingDocs.size){
            const docsToRemove = new Set();
            for (const doc of pendingDocs){
                const { status } = await _api.PipelinesService.getPipelineDocumentStatusApiV1PipelinesPipelineIdDocumentsDocumentIdStatusGet({
                    pipelineId,
                    documentId: doc
                });
                if (status === "NOT_STARTED" || status === "IN_PROGRESS") {
                    continue;
                }
                if (status === "ERROR") {
                    if (verbose) {
                        console.error(`Document ingestion failed for ${doc}`);
                    }
                    if (raiseOnError) {
                        throw new Error(`Document ingestion failed for ${doc}`);
                    }
                }
                docsToRemove.add(doc);
            }
            for (const doc of docsToRemove){
                pendingDocs.delete(doc);
            }
            if (pendingDocs.size) {
                if (verbose) {
                    process.stdout.write(".");
                }
                await new Promise((resolve)=>setTimeout(resolve, 500));
            }
        }
        if (verbose) {
            console.log("Done!");
        }
        await this.waitForPipelineIngestion(verbose, raiseOnError);
    }
    async getPipelineId(name, projectName) {
        const pipelines = await _api.PipelinesService.searchPipelinesApiV1PipelinesGet({
            projectName,
            pipelineName: name
        });
        return pipelines[0].id;
    }
    static async fromDocuments(params) {
        (0, _utils.initService)(params);
        const defaultTransformations = [
            new _nodeparser.SentenceSplitter(),
            new _OpenAIEmbedding.OpenAIEmbedding({
                apiKey: (0, _env.getEnv)("OPENAI_API_KEY")
            })
        ];
        const apiUrl = (0, _utils.getAppBaseUrl)();
        const pipelineCreateParams = await (0, _config.getPipelineCreate)({
            pipelineName: params.name,
            pipelineType: "MANAGED",
            inputNodes: params.documents,
            transformations: params.transformations ?? defaultTransformations
        });
        const project = await _api.ProjectsService.upsertProjectApiV1ProjectsPut({
            requestBody: {
                name: params.projectName ?? "default"
            }
        });
        if (!project.id) {
            throw new Error("Project ID should be defined");
        }
        const pipeline = await _api.PipelinesService.upsertPipelineApiV1PipelinesPut({
            projectId: project.id,
            requestBody: {
                name: params.name,
                configured_transformations: pipelineCreateParams.configured_transformations,
                pipeline_type: pipelineCreateParams.pipeline_type
            }
        });
        if (!pipeline.id) {
            throw new Error("Pipeline ID must be defined");
        }
        if (params.verbose) {
            console.log(`Created pipeline ${pipeline.id} with name ${params.name}`);
        }
        await _api.PipelinesService.upsertBatchPipelineDocumentsApiV1PipelinesPipelineIdDocumentsPut({
            pipelineId: pipeline.id,
            requestBody: params.documents.map((doc)=>({
                    metadata: doc.metadata,
                    text: doc.text,
                    excluded_embed_metadata_keys: doc.excludedEmbedMetadataKeys,
                    excluded_llm_metadata_keys: doc.excludedEmbedMetadataKeys,
                    id: doc.id_
                }))
        });
        while(true){
            const pipelineStatus = await _api.PipelinesService.getPipelineStatusApiV1PipelinesPipelineIdStatusGet({
                pipelineId: pipeline.id
            });
            if (pipelineStatus.status === "SUCCESS") {
                console.info("Documents ingested successfully, pipeline is ready to use");
                break;
            }
            if (pipelineStatus.status === "ERROR") {
                console.error(`Some documents failed to ingest, check your pipeline logs at ${apiUrl}/project/${project.id}/deploy/${pipeline.id}`);
                throw new Error("Some documents failed to ingest");
            }
            if (pipelineStatus.status === "PARTIAL_SUCCESS") {
                console.info(`Documents ingestion partially succeeded, to check a more complete status check your pipeline at ${apiUrl}/project/${project.id}/deploy/${pipeline.id}`);
                break;
            }
            if (params.verbose) {
                process.stdout.write(".");
            }
            await new Promise((resolve)=>setTimeout(resolve, 1000));
        }
        if (params.verbose) {
            console.info(`Ingestion completed, find your index at ${apiUrl}/project/${project.id}/deploy/${pipeline.id}`);
        }
        return new LlamaCloudIndex({
            ...params
        });
    }
    asRetriever(params = {}) {
        return new _LlamaCloudRetriever.LlamaCloudRetriever({
            ...this.params,
            ...params
        });
    }
    asQueryEngine(params) {
        const retriever = new _LlamaCloudRetriever.LlamaCloudRetriever({
            ...this.params,
            ...params
        });
        return new _RetrieverQueryEngine.RetrieverQueryEngine(retriever, params?.responseSynthesizer, params?.preFilters, params?.nodePostprocessors);
    }
    async insert(document) {
        const pipelineId = await this.getPipelineId(this.params.name, this.params.projectName);
        if (!pipelineId) {
            throw new Error("We couldn't find the pipeline ID for the given name");
        }
        await _api.PipelinesService.createBatchPipelineDocumentsApiV1PipelinesPipelineIdDocumentsPost({
            pipelineId: pipelineId,
            requestBody: [
                {
                    metadata: document.metadata,
                    text: document.text,
                    excluded_embed_metadata_keys: document.excludedLlmMetadataKeys,
                    excluded_llm_metadata_keys: document.excludedEmbedMetadataKeys,
                    id: document.id_
                }
            ]
        });
        await this.waitForDocumentIngestion([
            document.id_
        ]);
    }
    async delete(document) {
        const pipelineId = await this.getPipelineId(this.params.name, this.params.projectName);
        if (!pipelineId) {
            throw new Error("We couldn't find the pipeline ID for the given name");
        }
        await _api.PipelinesService.deletePipelineDocumentApiV1PipelinesPipelineIdDocumentsDocumentIdDelete({
            pipelineId,
            documentId: document.id_
        });
        await this.waitForPipelineIngestion();
    }
    async refreshDoc(document) {
        const pipelineId = await this.getPipelineId(this.params.name, this.params.projectName);
        if (!pipelineId) {
            throw new Error("We couldn't find the pipeline ID for the given name");
        }
        await _api.PipelinesService.upsertBatchPipelineDocumentsApiV1PipelinesPipelineIdDocumentsPut({
            pipelineId,
            requestBody: [
                {
                    metadata: document.metadata,
                    text: document.text,
                    excluded_embed_metadata_keys: document.excludedLlmMetadataKeys,
                    excluded_llm_metadata_keys: document.excludedEmbedMetadataKeys,
                    id: document.id_
                }
            ]
        });
        await this.waitForDocumentIngestion([
            document.id_
        ]);
    }
}
